{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from skimage import transform\n",
    "from skimage import filters\n",
    "from skimage import color\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import imageio\n",
    "import skimage\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float32\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_pics():\n",
    "    \n",
    "    X = []\n",
    "    Y = []\n",
    "    Z = []\n",
    "    f = open('micheI_sgs4.txt')\n",
    "       \n",
    "    counter = 0\n",
    "    for idx, l in enumerate(f):e\n",
    "        l = l.strip().split(' ')\n",
    "        name, x, y, r = l[0], int(l[1]), int(l[2]), int(l[3])\n",
    "        pic = imageio.imread('data/BipLab/SamsungGalaxyS4/' + name + '.jpg')\n",
    "        h, w, c = pic.shape\n",
    "        scale_factor = 160.0/h\n",
    "        pic_small = skimage.transform.resize(pic, (160,90,3))\n",
    "        new_r = int(r * scale_factor)\n",
    "        new_x = int(x * scale_factor)\n",
    "        new_y = int(y * scale_factor)\n",
    "        X.append(pic_small)\n",
    "        Y.append(new_r)\n",
    "        Z.append((new_x, new_y))\n",
    "        \n",
    "        if counter % 50 == 0:\n",
    "            print(counter)\n",
    "            fig, ax = plt.subplots(1)\n",
    "            plt.imshow(pic_small)\n",
    "            rect_true = patches.Rectangle((new_x-new_r,new_y-new_r),2*new_r,2*new_r, linewidth=1, edgecolor='r', facecolor='none')\n",
    "            ax.add_patch(rect_true)\n",
    "            plt.show()\n",
    "            \n",
    "        counter += 1\n",
    "            \n",
    "    return (X, Y, Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_sets(X, Y, Z):\n",
    "    \n",
    "    # Convert to np-arrays\n",
    "    X_np = np.array(X)\n",
    "    Y_np = np.array(Y)\n",
    "    print(\"Gen Sets: Original Shapes\")\n",
    "    print(X_np.shape)\n",
    "    print(Y_np.shape)\n",
    "\n",
    "    # Reshape to Correect Tensor Format\n",
    "    Xt = X_np.reshape((X_np.shape[0], 1, X_np.shape[3], X_np.shape[1], X_np.shape[2]))\n",
    "    Yt = Y_np.reshape(Y_np.shape[0], 1, 1)\n",
    "    print(\"Gen Sets: Reshaped Shapes\")\n",
    "    print(Xt.shape)\n",
    "    print(Yt.shape)\n",
    "    \n",
    "    # Define Split Boundaries\n",
    "    N = Xt.shape[0]\n",
    "    train = int(6*N/10)\n",
    "    val = int(7*N/10)\n",
    "    \n",
    "    # Train-Val-Test Partitioning\n",
    "    X_train = Xt[:train]\n",
    "    y_train = Yt[:train]\n",
    "    \n",
    "    X_val = Xt[train:val]\n",
    "    y_val = Yt[train:val]\n",
    "    \n",
    "    X_test = Xt[val:]\n",
    "    y_test = Yt[val:]\n",
    "    Z_test = Z[val:]\n",
    "    \n",
    "    # Convert to Torch Tensors\n",
    "    X_train = torch.tensor(X_train).type(torch.FloatTensor)\n",
    "    y_train = torch.tensor(y_train)\n",
    "    X_val = torch.tensor(X_val).type(torch.FloatTensor)\n",
    "    y_val = torch.tensor(y_val)\n",
    "    X_test = torch.tensor(X_test).type(torch.FloatTensor)\n",
    "    y_test = torch.tensor(y_test)\n",
    "\n",
    "    # Report Shapes\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(X_val.shape)\n",
    "    print(y_val.shape)\n",
    "    print(X_test.shape)\n",
    "    print(y_test.shape)\n",
    "    \n",
    "    return (X_train, y_train, X_val, y_val, X_test, y_test, Z_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(mode, model, verbose=False, margin=0):\n",
    "            \n",
    "    if mode == 'val':\n",
    "        X_sel = X_val\n",
    "        y_sel = y_val\n",
    "    elif mode == 'train':\n",
    "        X_sel = X_train\n",
    "        y_sel = y_train\n",
    "    else:\n",
    "        X_sel = X_test\n",
    "        y_sel = y_test\n",
    "    \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for t in range(X_sel.shape[0]):\n",
    "            \n",
    "            x = X_sel[t]\n",
    "            y = y_sel[t]\n",
    "            \n",
    "            x = x.to(device=device, dtype=dtype)\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            \n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            if abs(preds - y) <= margin:\n",
    "                num_correct += 1\n",
    "            num_samples += preds.size(0)\n",
    "            \n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f) for mode %s' % (num_correct, num_samples, 100 * acc, mode))\n",
    "    return 100*acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, epochs=20):\n",
    "    \n",
    "    model = model.to(device=device)\n",
    "    margins = 3\n",
    "    train_accs = [[] for _ in range(margins)]\n",
    "    val_accs = [[] for _ in range(margins)]\n",
    "    for e in range(epochs):\n",
    "        for t in range(X_train.shape[0]):\n",
    "            model.train() \n",
    "            \n",
    "            x = X_train[t]\n",
    "            y = y_train[t]\n",
    "            \n",
    "            x = x.to(device=device, dtype=dtype)\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            \n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y[0])\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % 200 == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "                print() \n",
    "        \n",
    "        print('epoch %d' % (e))\n",
    "        for m in range(margins):\n",
    "            print('With margin {}:'.format(m))\n",
    "            train_accs[m].append(check_accuracy('train', model, margin=m))\n",
    "            val_accs[m].append(check_accuracy('val', model, margin=m))\n",
    "        print()\n",
    "    fig, ax = plt.subplots(1, margins, sharey=True)\n",
    "    for m in range(margins):\n",
    "        ax[m].plot(train_accs[m])\n",
    "        ax[m].plot(val_accs[m])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    return x.view(x.shape[0] , -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    \n",
    "    channel_1 = 32\n",
    "    channel_2 = 32\n",
    "    channel_3 = 32\n",
    "    channel_4 = 16\n",
    "    channel_5 = 16\n",
    "\n",
    "    model1 = nn.Sequential(\n",
    "        nn.Conv2d(3, 64, kernel_size=10, padding=0, stride=10),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout2d(0.5),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "\n",
    "        Flatten(),\n",
    "        nn.Linear(2048, 625),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(625, 45)\n",
    "    )\n",
    "    \n",
    "    model2 = nn.Sequential(\n",
    "        nn.Conv2d(3, 64, kernel_size=5, padding=0, stride=1),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout2d(0.2),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "        \n",
    "        nn.Conv2d(64, 16, 3, padding=1),\n",
    "        nn.BatchNorm2d(16),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout2d(0.2),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "\n",
    "        Flatten(),\n",
    "        nn.Linear(13104, 1000),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(1000, 45)\n",
    "    )\n",
    "    \n",
    "    model3 = nn.Sequential(\n",
    "        nn.Conv2d(3, 32, kernel_size=5, padding=0, stride=1),\n",
    "        nn.BatchNorm2d(32),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout2d(0.5),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "        \n",
    "        nn.Conv2d(32, 32, 3, padding=1),\n",
    "        nn.BatchNorm2d(32),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout2d(0.5),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "        \n",
    "        nn.Conv2d(32, 16, 3, padding=0),\n",
    "        nn.BatchNorm2d(16),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout2d(0.5),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "\n",
    "        Flatten(),\n",
    "        nn.Linear(2592, 676),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(676, 45)\n",
    "    )\n",
    "    \n",
    "    model4 = nn.Sequential(\n",
    "        nn.Conv2d(3, 32, kernel_size=5, padding=0, stride=1),\n",
    "        nn.BatchNorm2d(32),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout2d(0.2),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "        \n",
    "        nn.Conv2d(32, 32, 3, padding=1),\n",
    "        nn.BatchNorm2d(32),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout2d(0.2),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "        \n",
    "        nn.Conv2d(32, 16, 3, padding=0),\n",
    "        nn.BatchNorm2d(16),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout2d(0.5),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "\n",
    "        Flatten(),\n",
    "        nn.Linear(2592, 676),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        \n",
    "        nn.Linear(676, 100),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        \n",
    "        nn.Linear(100, 45)\n",
    "    )\n",
    "    \n",
    "    model5 = nn.Sequential(\n",
    "        nn.Conv2d(3, 32, kernel_size=5, padding=0, stride=1),\n",
    "        nn.BatchNorm2d(32),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout2d(0.5),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "        \n",
    "        nn.Conv2d(32, 32, 5, padding=1),\n",
    "        nn.BatchNorm2d(32),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout2d(0.5),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "        \n",
    "        nn.Conv2d(32, 16, 3, padding=0),\n",
    "        nn.BatchNorm2d(16),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout2d(0.5),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "\n",
    "        Flatten(),\n",
    "        nn.Linear(2592, 676),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        \n",
    "        nn.Linear(676, 100),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        \n",
    "        nn.Linear(100, 45)\n",
    "    )\n",
    "\n",
    "    #optimizer = optim.SGD(model.parameters(), lr=1e-4, momentum=0.9, nesterov=True)\n",
    "    optimizer1 = optim.Adam(model1.parameters(), lr=1e-4, betas=(0.9, 0.999))\n",
    "    optimizer2 = optim.Adam(model2.parameters(), lr=1e-4, betas=(0.9, 0.999))\n",
    "    optimizer3 = optim.Adam(model3.parameters(), lr=1e-4, betas=(0.9, 0.999))\n",
    "    optimizer4 = optim.Adam(model4.parameters(), lr=1e-4, betas=(0.9, 0.999))\n",
    "    optimizer5 = optim.Adam(model5.parameters(), lr=1e-4, betas=(0.9, 0.999))\n",
    "    train(model1, optimizer1, epochs=20)\n",
    "    train(model2, optimizer2, epochs=20)\n",
    "    train(model3, optimizer3, epochs=20)\n",
    "    train(model4, optimizer4, epochs=20)\n",
    "    train(model5, optimizer5, epochs=20)\n",
    "    return [model1, model2, model3, model4, model5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluation(Z_test, model):\n",
    "    \n",
    "    dist = []\n",
    "    for image_idx in range(X_test.shape[0]):\n",
    "\n",
    "        (x, y) = Z_test[image_idx]\n",
    "        r_true = y_test[image_idx].item()\n",
    "        r_pred = np.argmax(np.array(model(X_test[image_idx]).data))\n",
    "        dist.append(abs(r_true - r_pred))\n",
    "       \n",
    "        if(image_idx % 100 == 0):\n",
    "            fig, ax = plt.subplots(1)\n",
    "            plt.imshow(X_test[image_idx,0,:,:,:].reshape(160,90,3))\n",
    "            rect_true = patches.Rectangle((x-r_true,y-r_true),2*r_true,2*r_true, linewidth=3, edgecolor='r', facecolor='none')\n",
    "            rect_pred = patches.Rectangle((x-r_pred,y-r_pred),2*r_pred,2*r_pred, linewidth=1, edgecolor='b', facecolor='none')\n",
    "            ax.add_patch(rect_true)\n",
    "            ax.add_patch(rect_pred)\n",
    "            plt.show()\n",
    "\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load Initial Datasets\n",
    "X, Y, Z = load_pics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the Model\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, Z_test = gen_sets(X, Y, Z)\n",
    "models = train_model()\n",
    "for model in models:\n",
    "    check_accuracy('test', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    check_accuracy('test', model, margin=0)\n",
    "    check_accuracy('test', model, margin=1)\n",
    "    check_accuracy('test', model, margin=2)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Update the Datasets with New Negative Examples\n",
    "for model in models:\n",
    "    dist = evaluation(Z_test, model)\n",
    "    plt.hist(np.array(dist))\n",
    "    plt.title('Training Set Model Analysis')\n",
    "    plt.xlabel('Euclidean Distances to Ground-Truth Radius')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
