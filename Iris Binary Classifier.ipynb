{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from operator import itemgetter\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from skimage import transform\n",
    "from skimage import filters\n",
    "from skimage import color\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import imageio\n",
    "import skimage\n",
    "import glob\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float32 \n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_pics():\n",
    "    \n",
    "    X = []\n",
    "    Y = []\n",
    "    test_set_images = []\n",
    "    test_set_truths = []\n",
    "    train_set_images = []\n",
    "    train_set_truths = []\n",
    "    num_falses_per_true = 4\n",
    "    f = open('micheI_sgs4.txt')\n",
    "       \n",
    "    counter = 0\n",
    "    for idx, l in enumerate(f):\n",
    "\n",
    "        l = l.strip().split(' ')\n",
    "        name, y, x, r = l[0], int(l[1]), int(l[2]), int(l[3])\n",
    "        pic = imageio.imread('SamsungGalaxyS4/' + name + '.jpg')\n",
    "        h, w, c = pic.shape\n",
    "        \n",
    "        if idx > 907: \n",
    "            scale_factor = 160.0/h\n",
    "            pic_small = skimage.transform.resize(pic, (160,90,3))\n",
    "            new_r = int(r * scale_factor)\n",
    "            new_x = int(x * scale_factor)\n",
    "            new_y = int(y * scale_factor)\n",
    "            test_set_images.append(pic_small)\n",
    "            test_set_truths.append((new_r, new_x, new_y))\n",
    "            \n",
    "        if idx < 778:\n",
    "            scale_factor = 160.0/h\n",
    "            pic_small = skimage.transform.resize(pic, (160,90,3))\n",
    "            new_r = int(r * scale_factor)\n",
    "            new_x = int(x * scale_factor)\n",
    "            new_y = int(y * scale_factor)\n",
    "            train_set_images.append(pic_small)\n",
    "            train_set_truths.append((new_r, new_x, new_y))\n",
    "            \n",
    "        iris = pic[x-r:x+r,y-r:y+r,:]\n",
    "        iris_scale = skimage.transform.resize(iris, (32,32,3))  \n",
    "        X.append(iris_scale)\n",
    "        Y.append(1)\n",
    "       \n",
    "        for _ in range(num_falses_per_true):\n",
    "            corner_x = np.random.randint(0, h - 2*r)\n",
    "            corner_y = np.random.randint(0, w - 2*r)\n",
    "            while abs(corner_x - (x-r)) < r and abs(corner_y - (y-r)) < r:\n",
    "                corner_x = np.random.randint(0, h - r)\n",
    "                corner_y = np.random.randint(0, w - r)\n",
    "        \n",
    "            not_iris = pic[corner_x:corner_x+2*r, corner_y:corner_y+2*r,:]\n",
    "            not_iris_scale = skimage.transform.resize(not_iris, (32,32,3))\n",
    "        \n",
    "            X.append(not_iris_scale)\n",
    "            Y.append(0)\n",
    "        \n",
    "        counter += 1\n",
    "        if counter % 10 == 0:\n",
    "            print(counter)\n",
    "           \n",
    "        if counter % 100 == 0:\n",
    "            plt.imshow(pic)\n",
    "            plt.show()\n",
    "            plt.imshow(iris_scale)\n",
    "            plt.show()\n",
    "            plt.imshow(not_iris_scale)\n",
    "            plt.show()\n",
    "    \n",
    "    \n",
    "    return (train_set_images, train_set_truths, test_set_images, test_set_truths, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_sets(X, Y, num_new = 0):\n",
    "    \n",
    "    # Convert to np-arrays\n",
    "    X_np = np.array(X)\n",
    "    Y_np = np.array(Y)\n",
    "    print(\"Gen Sets: Original Shapes\")\n",
    "    print(X_np.shape)\n",
    "    print(Y_np.shape)\n",
    "    \n",
    "    # Reshape to Correect Tensor Format\n",
    "    Xt = X_np.reshape((X_np.shape[0], 1, X_np.shape[3], X_np.shape[1], X_np.shape[2]))\n",
    "    Yt = Y_np.reshape(Y_np.shape[0], 1, 1)\n",
    "    print(\"Gen Sets: Reshaped Shapes\")\n",
    "    print(Xt.shape)\n",
    "    print(Yt.shape)\n",
    "    \n",
    "    # Train-Val-Test Partitioning\n",
    "    N = Xt.shape[0]\n",
    "    train = int(6*(N-num_new)/10) + num_new\n",
    "    val = int(7*(N-num_new)/10) + num_new\n",
    "    X_train = Xt[:train]\n",
    "    X_val = Xt[train:val]\n",
    "    X_test = Xt[val:]\n",
    "    y_train = Yt[:train]\n",
    "    y_val = Yt[train:val]\n",
    "    y_test = Yt[val:]\n",
    "\n",
    "    # Convert to Torch Tensors\n",
    "    X_train = torch.tensor(X_train).type(torch.FloatTensor)\n",
    "    y_train = torch.tensor(y_train)\n",
    "    X_val = torch.tensor(X_val).type(torch.FloatTensor)\n",
    "    y_val = torch.tensor(y_val)\n",
    "    X_test = torch.tensor(X_test).type(torch.FloatTensor)\n",
    "    y_test = torch.tensor(y_test)\n",
    "\n",
    "    # Report Shapes\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(X_val.shape)\n",
    "    print(y_val.shape)\n",
    "    print(X_test.shape)\n",
    "    print(y_test.shape)\n",
    "    \n",
    "    return (X_train, y_train, X_val, y_val, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(mode, model, verbose=False):\n",
    "            \n",
    "    if mode == 'val':\n",
    "        X_sel = X_val\n",
    "        y_sel = y_val\n",
    "    elif mode == 'train':\n",
    "        X_sel = X_train\n",
    "        y_sel = y_train\n",
    "    else:\n",
    "        X_sel = X_test\n",
    "        y_sel = y_test\n",
    "    \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for t in range(X_sel.shape[0]):\n",
    "            \n",
    "            x = X_sel[t]\n",
    "            y = y_sel[t]\n",
    "            \n",
    "            x = x.to(device=device, dtype=dtype)\n",
    "            y = y.to(device=device, dtype=dtype)\n",
    "            \n",
    "            preds = 1 if model(x).item() > 0.5 else 0\n",
    "            num_correct += (preds == y.item())\n",
    "            if verbose and y.item() != preds:\n",
    "                plt.imshow(np.array(x.detach())[0].reshape((32,32,3)))\n",
    "                plt.show()\n",
    "            num_samples += 1\n",
    "            \n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f) for mode %s' % (num_correct, num_samples, 100 * acc, mode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, epochs=20):\n",
    "    \n",
    "    model = model.to(device=device)\n",
    "    for e in range(epochs):\n",
    "        for t in range(X_train.shape[0]):\n",
    "            model.train() \n",
    "            \n",
    "            x = X_train[t]\n",
    "            y = y_train[t]\n",
    "            \n",
    "            x = x.to(device=device, dtype=dtype)\n",
    "            y = y.to(device=device, dtype=dtype)\n",
    "            \n",
    "            scores = model(x)\n",
    "            loss = F.binary_cross_entropy(scores, y)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % 500 == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "                print() \n",
    "        \n",
    "        print('epoch %d' % (e))\n",
    "        check_accuracy('train', model)\n",
    "        check_accuracy('val', model)\n",
    "        print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    return x.view(x.shape[0] , -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    \n",
    "    channel_1 = 32\n",
    "    channel_2 = 16\n",
    "\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv2d(3, channel_1, kernel_size=5, padding=0, stride=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "        nn.Conv2d(channel_1, channel_2, 3, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "        Flatten(),\n",
    "        nn.Linear(784, 100),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(100, 1),\n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=0.9, nesterov=True)\n",
    "    train(model, optimizer, epochs=20)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_gaussian(num_sampled):\n",
    "    \n",
    "    dist = []\n",
    "\n",
    "    print(\"Began Iterations\")\n",
    "    for image_idx, pic_small in enumerate(test_set_images):\n",
    "\n",
    "        if (image_idx % 100 == 0):\n",
    "            print(\"Processing Image Index: %d\" % image_idx);\n",
    "        (new_r, new_x, new_y) = test_set_truths[image_idx]\n",
    "        \n",
    "        scores = []\n",
    "        for sampling in range(num_sampled):\n",
    "            mean = [80 - new_r, 45-new_r]\n",
    "            cov = [[new_r, 0], [0, new_r]]\n",
    "            i, j = np.random.multivariate_normal(mean, cov)\n",
    "            i = int(i)\n",
    "            j = int(j)\n",
    "            if i >= 0 and i < 160 - 2*new_r and j >= 0 and j < 90 - 2*new_r:\n",
    "                model_in = skimage.transform.resize(pic_small[i:i+2*new_r,j:j+2*new_r,:], (32,32,3))\n",
    "                score = model(torch.tensor(model_in.reshape((1, 3, 32, 32))).type(torch.FloatTensor))\n",
    "                scores.append((i,j,score))\n",
    "            \n",
    "        c_xy = max(scores,key=itemgetter(2))\n",
    "        c_x, c_y = c_xy[0], c_xy[1]\n",
    "        dist.append(np.sqrt((c_y - (new_y - new_r))**2 + (c_x - (new_x - new_r))**2))\n",
    "    \n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_uniform(num_sampled):\n",
    "    \n",
    "    dist = []\n",
    "    print(\"Began Iterations\")\n",
    "    for image_idx, pic_small in enumerate(test_set_images):\n",
    "\n",
    "        if (image_idx % 100 == 0):\n",
    "            print(\"Processing Image Index: %d\" % image_idx);\n",
    "        (new_r, new_x, new_y) = test_set_truths[image_idx]\n",
    "        \n",
    "        scores = []\n",
    "        for sampling in range(num_sampled):\n",
    "            i = np.random.randint(0, 160 - 2*new_r)\n",
    "            j = np.random.randint(0, 90 - 2*new_r)\n",
    "            model_in = skimage.transform.resize(pic_small[i:i+2*new_r,j:j+2*new_r,:], (32,32,3))\n",
    "            score = model(torch.tensor(model_in.reshape((1, 3, 32, 32))).type(torch.FloatTensor))\n",
    "            scores.append((i,j,score))\n",
    "            \n",
    "        c_xy = max(scores,key=itemgetter(2))\n",
    "        c_x, c_y = c_xy[0], c_xy[1]\n",
    "        dist.append(np.sqrt((c_y - (new_y - new_r))**2 + (c_x - (new_x - new_r))**2))\n",
    "    \n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_test():\n",
    "    \n",
    "    dist = []\n",
    "    print(\"Began Iterations\")\n",
    "    for image_idx, pic_small in enumerate(test_set_images):\n",
    "\n",
    "        print(\"Processing Image Index: %d\" % image_idx);\n",
    "        (new_r, new_x, new_y) = test_set_truths[image_idx]\n",
    "        scores = np.zeros((160-2*new_r,90-2*new_r))\n",
    "        for ic, i in enumerate(range(160-2*new_r)):\n",
    "            for jc, j in enumerate(range(90-2*new_r)):\n",
    "                model_in = skimage.transform.resize(pic_small[i:i+2*new_r,j:j+2*new_r,:], (32,32,3))\n",
    "                score = model(torch.tensor(model_in.reshape((1, 3, 32, 32))).type(torch.FloatTensor))\n",
    "                scores[ic,jc] = score.item()\n",
    "\n",
    "        c_x, c_y = np.unravel_index(np.argmax(scores), scores.shape)\n",
    "        dist.append(np.sqrt((c_y - (new_y - new_r))**2 + (c_x - (new_x - new_r))**2))\n",
    "\n",
    "        if image_idx % 1 == 0:\n",
    "            plt.imshow(scores)\n",
    "            fig, ax = plt.subplots(1)\n",
    "            plt.imshow(pic_small)\n",
    "            rect_true = patches.Rectangle((new_y-new_r,new_x-new_r),2*new_r,2*new_r, linewidth=6, edgecolor='r', facecolor='none')\n",
    "            rect_pred = patches.Rectangle((c_y, c_x), 2*new_r, 2*new_r, linewidth=1, edgecolor='b', facecolor='none')\n",
    "            ax.add_patch(rect_true)\n",
    "            ax.add_patch(rect_pred)\n",
    "            plt.show()\n",
    "\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluation_train():\n",
    "    \n",
    "    dist = []\n",
    "    num_new = 0\n",
    "    print(\"Began Iterations\")\n",
    "    for image_idx, pic_small in enumerate(train_set_images):\n",
    "\n",
    "        print(\"Processing Image Index: %d\" % image_idx);\n",
    "        (new_r, new_x, new_y) = train_set_truths[image_idx]\n",
    "        \n",
    "        scores = []\n",
    "        for sampling in range(500):\n",
    "            i = np.random.randint(0, 160 - 2*new_r)\n",
    "            j = np.random.randint(0, 90 - 2*new_r)\n",
    "            model_in = skimage.transform.resize(pic_small[i:i+2*new_r,j:j+2*new_r,:], (32,32,3))\n",
    "            score = model(torch.tensor(model_in.reshape((1, 3, 32, 32))).type(torch.FloatTensor))\n",
    "            scores.append((i,j,score))\n",
    "            \n",
    "        c_xy = max(scores,key=itemgetter(2))\n",
    "        c_x, c_y = c_xy[0], c_xy[1]\n",
    "        dist.append(np.sqrt((c_y - (new_y - new_r))**2 + (c_x - (new_x - new_r))**2))\n",
    "\n",
    "        if dist[-1] > 5.0:\n",
    "            num_new = num_new + 1\n",
    "            print(\"Classified Wrong (Distance %f)\" % float(dist[-1]))\n",
    "            predicted_image = skimage.transform.resize(pic_small[c_x:c_x+2*new_r,c_y:c_y+2*new_r,:], (32,32,3))\n",
    "            X.insert(0, predicted_image)\n",
    "            Y.insert(0, 0)\n",
    "            \n",
    "        if image_idx % 1 == 0:\n",
    "            fig, ax = plt.subplots(1)\n",
    "            plt.imshow(pic_small)\n",
    "            rect_true = patches.Rectangle((new_y-new_r,new_x-new_r),2*new_r,2*new_r, linewidth=6, edgecolor='r', facecolor='none')\n",
    "            rect_pred = patches.Rectangle((c_y, c_x), 2*new_r, 2*new_r, linewidth=1, edgecolor='b', facecolor='none')\n",
    "            ax.add_patch(rect_true)\n",
    "            ax.add_patch(rect_pred)\n",
    "            plt.show()\n",
    "\n",
    "    return (num_new, dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Initial Datasets\n",
    "train_set_images, train_set_truths, test_set_images, test_set_truths, X_og, Y_og = load_pics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train the Model\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = gen_sets(X_og, Y_og, 0)\n",
    "model = train_model()\n",
    "check_accuracy('test', model, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Update the Datasets with New Negative Examples\n",
    "num_new, dist = evaluation_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.array(dist))\n",
    "plt.title('Training Set Model Analysis')\n",
    "plt.xlabel('Euclidean Distances to Ground-Truth Corner')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "print(num_new)\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain Model\n",
    "print(num_new)\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = gen_sets(X, Y, num_new)\n",
    "model = train_model()\n",
    "check_accuracy('test', model, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Analyze on Test Set\n",
    "dist = evaluation_test()\n",
    "dist_uni = evaluation_uniform(1000)\n",
    "dist_gauss = evaluation_gaussian(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.array(dist))\n",
    "plt.title('Test Set Model Analysis')\n",
    "plt.xlabel('Euclidean Distances to Ground-Truth Corner')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "print(num_new)\n",
    "print(dist)\n",
    "print(dist_uni)\n",
    "print(dist_gauss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
